{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import autograd\n",
    "from datetime import datetime\n",
    "from statistics import mean, stdev\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import logging\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import csv\n",
    "\n",
    "seed = int(time.time())\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class encoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(encoder, self).__init__()\n",
    "        self.linear = nn.Linear(in_features=numberColumns, out_features=linearChannels, bias=True).to(device)\n",
    "        self.position = nn.Linear(1, linearChannels).to(device)\n",
    "        self.convolutions = nn.ModuleList([nn.Conv1d(in_channels = convolutionalChannels, \n",
    "                                                 out_channels = convolutionalChannels*2, kernel_size = kernelSize, \n",
    "                                                 padding = (kernelSize - 1) // 2) for _ in range(5)]).to(device)\n",
    "        self.toHidden = nn.Linear(linearChannels, convolutionalChannels).to(device)\n",
    "        self.fromHidden = nn.Linear(convolutionalChannels, linearChannels).to(device)\n",
    "        self.dropout = nn.Dropout().to(device)\n",
    "        \n",
    "    def forward(self, seriesInput, batch):\n",
    "        linearOutput = torch.unsqueeze(self.linear(seriesInput.to(device)), 2)\n",
    "        positionSeries = torch.arange((batch-1) * linearOutput.size()[0], \n",
    "                                      batch * linearOutput.size()[0]).unsqueeze(1).float().to(device)\n",
    "        positionEmbedded = self.position(positionSeries/len(normalizedDataset)).unsqueeze(1).permute(0, 2, 1)\n",
    "        embedded = self.dropout(linearOutput + positionEmbedded).permute(0, 2, 1)\n",
    "        convolutionInput = torch.unsqueeze(self.toHidden(embedded.squeeze()), 2)\n",
    "    \n",
    "        for i, convolution in enumerate(self.convolutions):\n",
    "            convolutionHidden = F.glu(convolution(self.dropout(convolutionInput)), dim = 1)\n",
    "            convolutionHidden = convolutionHidden + convolutionInput\n",
    "            convolutionInput = convolutionHidden\n",
    "        \n",
    "        convolutionHidden = self.fromHidden(convolutionHidden.permute(0, 2, 1))\n",
    "        residualConnection = convolutionHidden + embedded\n",
    "        return convolutionHidden, residualConnection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(decoder, self).__init__()\n",
    "        self.linear = nn.Linear(in_features=linearChannels, out_features=attentionChannels, bias=True).to(device)\n",
    "        self.position = nn.Embedding(linearChannels, attentionChannels).to(device)\n",
    "        self.convolutions = nn.ModuleList([nn.Conv1d(in_channels = convolutionalChannels, \n",
    "                                                     out_channels = convolutionalChannels*2, \n",
    "                                                     kernel_size = kernelSize) for _ in range(5)]).to(device)\n",
    "        self.toHidden = nn.Linear(attentionChannels, convolutionalChannels).to(device)\n",
    "        self.fromHidden = nn.Linear(convolutionalChannels, attentionChannels).to(device)\n",
    "        self.attentiontoHidden = nn.Linear(attentionChannels, convolutionalChannels).to(device)\n",
    "        self.attentionfromHidden = nn.Linear(convolutionalChannels, attentionChannels).to(device)\n",
    "        self.dropout = nn.Dropout().to(device)\n",
    "        self.output = nn.Linear(attentionChannels, numberColumns).to(device)\n",
    "        \n",
    "    def calculateAttention(self, embedded, convolutionHidden, encoderConvolutionHidden, encoderResidualConnection):\n",
    "        residualConnection = self.attentionfromHidden(convolutionHidden.permute(0, 2, \n",
    "                                                                                1)).squeeze() + embedded.squeeze()\n",
    "        attention = F.softmax(torch.matmul(residualConnection.permute(1, 0), \n",
    "                                           encoderConvolutionHidden.squeeze()), dim=1)\n",
    "        attentionEncoded = self.attentiontoHidden(torch.matmul(attention, encoderResidualConnection.squeeze()\n",
    "                                                               .permute(1,0)).permute(1,0))\n",
    "        attentionConnection = convolutionHidden.squeeze() + attentionEncoded\n",
    "        return attention, attentionConnection\n",
    "\n",
    "    def forward(self, hiddenEncoder, residualEncoder):\n",
    "        linearInput = torch.unsqueeze(self.linear(torch.squeeze(hiddenEncoder)), 2)\n",
    "        positionSeries = torch.arange(0, hiddenEncoder.shape[1]).unsqueeze(0).repeat(linearInput.size()[0], \n",
    "                                                                                     1).to(device)\n",
    "        positionEmbedded = self.position(positionSeries).permute(0, 2, 1)\n",
    "        embedded = self.dropout(linearInput + positionEmbedded)\n",
    "        convolutionInput = self.toHidden(embedded.squeeze())\n",
    "        \n",
    "        for i, convolution in enumerate(self.convolutions):\n",
    "            convolutionInput = self.dropout(torch.unsqueeze(convolutionInput, 2))\n",
    "            padding = torch.zeros(convolutionInput.size()[0], 128, 3-1).fill_(1).to(device)\n",
    "            paddedConvolutionInput = torch.cat((padding, convolutionInput), dim = 2)\n",
    "            convolutionHidden = F.glu(convolution(paddedConvolutionInput), dim = 1)\n",
    "            attention, convolutionHidden = self.calculateAttention(embedded, convolutionHidden, \n",
    "                                                                    hiddenEncoder, residualEncoder)\n",
    "            convolutionHidden = convolutionHidden + convolutionInput.squeeze()\n",
    "            convolutionInput = convolutionHidden\n",
    "            \n",
    "        output = self.output(self.dropout(self.fromHidden(convolutionHidden)))\n",
    "        stdMean = torch.std_mean(output)\n",
    "        normalizedDecoder = ((output - stdMean[1])/stdMean[0])\n",
    "        return normalizedDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFunction1 = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "lossFunction = nn.L1Loss()\n",
    "lossFunction3 = nn.PoissonNLLLoss()\n",
    "lossFunction4 = nn.MSELoss()\n",
    "\n",
    "def diversityLoss(input, target, iteration):\n",
    "    sizeInput = input.size()[0]\n",
    "    #rangeEnsemble = torch.tensor([outputCycle[k] for k in range((iteration-1) * sizeInput,iteration * sizeInput)])\n",
    "    #lossDiversity = loss_function(input, target) #- diversityFactor * torch.norm(input - rangeEnsemble, 2)/sizeInput\n",
    "    normResults = torch.zeros(1, 1).to(device)\n",
    "    for i in range(0,cycle):\n",
    "        #indices = torch.arange(iteration * sizeInput, (iteration+1) * sizeInput).to(device)\n",
    "        #rangeEnsemble = torch.index_select(outputCycle[i], 0, indices).to(device)\n",
    "        \n",
    "        #rangeEnsemble = torch.tensor([outputCycle[i][k] for k in range((iteration-1) * sizeInput,iteration * sizeInput)])\n",
    "        #normResults += torch.norm(input - rangeEnsemble, 2).to(device)/sizeInput\n",
    "        normResults += torch.norm(input - outputCycle[i], 2).to(device)/sizeInput\n",
    "        #print(normResults)\n",
    "        \n",
    "    lossDiversity = lossFunction(input, target) - diversityFactor * normResults\n",
    "\n",
    "    return lossDiversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VariableLR(initialLR, currentEpoch, epochPerCycle):\n",
    "    return initialLR * (np.cos(np.pi * currentEpoch / epochPerCycle) + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pot_eval(init_score, score, q=1e-3, level=0.01):\n",
    "    s = SPOT(q)  # SPOT object\n",
    "    s.fit(init_score, score)  # data import\n",
    "    s.initialize(level=level)  # initialization step\n",
    "    ret = s.run()  # run\n",
    "    pot_th = np.mean(ret['thresholds'])\n",
    "   \n",
    "    print('POT result: ', pot_th)\n",
    "    return pot_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading(encoderName,decoderName):\n",
    "\n",
    "    encoder_eval = encoder()\n",
    "    decoder_eval = decoder()\n",
    "\n",
    "    encoder_eval.load_state_dict(torch.load(os.path.join(\"./ModelsSMD\", encoderName)))\n",
    "    decoder_eval.load_state_dict(torch.load(os.path.join(\"./ModelsSMD\", decoderName)))\n",
    "\n",
    "    data = autograd.Variable(torchDataset)\n",
    "\n",
    "    encoder_eval.eval()\n",
    "    decoder_eval.eval()\n",
    "\n",
    "    a, b = encoder_eval(data,1)\n",
    "    reconstruction = decoder_eval(a, b)\n",
    "\n",
    "    normDifferences = torch.norm(reconstruction - torchDataset, dim=1)\n",
    "\n",
    "    score = zscore(normDifferences.tolist())\n",
    "    outlierPred_Normal = []\n",
    "    outlierPred_Automatic = []\n",
    "\n",
    "    thresholdNormal = 2.5 \n",
    "    for i in range (len(score)):\n",
    "        if score[i] < thresholdNormal:\n",
    "            outlierPred_Normal.append(1)\n",
    "        else:\n",
    "            outlierPred_Normal.append(-1)\n",
    "\n",
    "    with open(\"./SMDReview/\"+encoderName[8:-4]+\".csv\", 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(zip(score, outlierPred_Normal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberEpochs = 10\n",
    "cycles = 10\n",
    "beta = 0.9\n",
    "diversityFactor = 0.8\n",
    "learningRate = 0.001\n",
    "linearChannels = 64\n",
    "convolutionalChannels = 128\n",
    "attentionChannels = int(convolutionalChannels/2)\n",
    "kernelSize = 3\n",
    "\n",
    "filesPath = \"./SMD/SMDSeries/\"\n",
    "onlyfiles = [f for f in listdir(filesPath) if isfile(join(filesPath, f))]\n",
    "\n",
    "for nameFile in onlyfiles:\n",
    "    #importedData = pd.read_csv(filesPath + nameFile) #Yahoo\n",
    "    #attributes = ['value']\n",
    "    #importedData = importedData[attributes]\n",
    "\n",
    "    #importedData = pd.read_csv(filesPath + nameFile, header=None) #ECG\n",
    "    #importedData = importedData.iloc[:, 1:-1] #ECG\n",
    "    \n",
    "    #importedData = pd.read_csv(filesPath + nameFile) #Donut\n",
    "    #attributes = ['value']\n",
    "    #importedData = importedData[attributes]\n",
    "    \n",
    "    importedData = pd.read_csv(filesPath + nameFile,header=None) #SMD\n",
    "    \n",
    "    numberColumns = len(importedData.columns)\n",
    "    values = importedData + 1e-7\n",
    "    meanImported = np.mean(values)\n",
    "    stdImported = np.std(values)\n",
    "    normalizedDataset = ((values - meanImported)/stdImported).fillna(0)\n",
    "    torchDataset = torch.from_numpy(normalizedDataset.values).float().to(device)\n",
    "    dataloader = DataLoader(torchDataset, batch_size=len(normalizedDataset), shuffle=True)\n",
    "\n",
    "    for file in sorted(os.listdir(\"./ModelsSMD/\")):\n",
    "        if file.startswith(\"Encoder_\"+nameFile):\n",
    "            loading(file,\"De\"+file[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
